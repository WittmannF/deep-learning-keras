{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WittmannF/udemy-deep-learning/blob/master/section-2/toy_problem_blank.ipynb\" target=\"_parent\"> <img src =\" https://colab.research.google.com/assets/colab-badge.svg\" alt = \"Open In Colab\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7a4139FPMIc"
   },
   "source": [
    "# Codificação uma rede Problema Toy Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWEfDAEePLJW"
   },
   "source": [
    "Vamos usar o mesmo exemplo que temos visto no vídeo anterior com o preço de casa com base em sua área:\n",
    "! [input-example](https://user-images.githubusercontent.com/5733246/52136634-a2e8e080-262f-11e9-8f7a-61d79831d83d.png)\n",
    "Normalmente, quando se trabalha com problemas de aprendizagem de máquina ou profunda aprendizagem, você terá que seguir esses cinco passos:\n",
    "1. Explorando os dados\n",
    "- importação de dados\n",
    "- Compreender os dados\n",
    "2. Preparar os dados\n",
    "- Scaling\n",
    "- Transformando\n",
    "- One-Hot Encoding\n",
    "- Train teste de divisão /\n",
    "3. Desenvolver um modelo básico\n",
    "4. Previsões Verificação\n",
    "5. Resultados de Melhoria\n",
    "Vamos verificar alguns deles aqui!\n",
    "## 1. importar os dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOIDW9boibxW"
   },
   "source": [
    "Vamos criar um conjunto de dados brinquedo com apenas 20 áreas e 20 preços"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDaYfd4yD2Lj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpettqxCD2L8"
   },
   "source": [
    "## 2. Preparar os dados de\n",
    "### Escala numérica Características\n",
    "Otimizadores geralmente funcionam melhor quando os intervalos de dados de entrada a partir de qualquer uma ou -1 para 0 a 1. Isto ajuda a superfície de erro para aproximar mais rápido para a sua mínimos global. Para melhores resultados, o [Standardization](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) é altamente sugerido por ter um conjunto de dados com média igual a zero e um desvio padrão de 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSO0XZn8ibxu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0CxDqZbD2MQ"
   },
   "source": [
    "### de dados dividindo-se em conjuntos de treinamento e teste\n",
    "Além de escalar os dados, é muito importante para dividir o conjunto de dados para treinamento e testes subconjuntos. O conjunto de treinamento vai ser usado para definir o modelo (ou o limite de decisão) e o conjunto de teste vai ser usado para avaliar o seu desempenho em dados invisíveis. Se não utilizar um conjunto de teste, há um risco de overfitting ** ** que é ilustrado na imagem a seguir:\n",
    "! [underfit](https://user-images.githubusercontent.com/5733246/52140129-23600f00-2639-11e9-8c03-308823791377.png)\n",
    "A divisão de trem / teste pode ser realizado utilizando train_test_split de sklearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmBmrkd4D2MR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPiwW_lsQXV8"
   },
   "source": [
    "## 3. Desenvolver um modelo básico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujJ0SqAOD2Mh"
   },
   "source": [
    "Vamos agora usar Keras, a fim de construir o nosso primeiro modelo. Primeiro de tudo, [why keras instead of Tensorflow?](https://colab.research.google.com/drive/14JiUzHH2jaFixSOOuWPwKTfj2fXuwD8Q).\n",
    "Ao definir um modelo, há três componentes principais que você tem que estar ciente:\n",
    "A arquitetura de 1. Modelo: Como são camadas empilhadas umas sobre as outras? Quais camadas estão indo para ser usado?\n",
    "- Documentação de Camadas: https://keras.io/layers/core/\n",
    "- Guia de modelos sequenciais: https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "2. Optimizers e função de perda.\n",
    "- Documentação de otimizadores: https://keras.io/optimizers/\n",
    "- Documentação de tipos de funções de perda: https://keras.io/losses/\n",
    "- método de compilação: https://keras.io/models/sequential/#compile\n",
    "3. Formação do modelo\n",
    "- método Fit: https://keras.io/models/sequential/#fit\n",
    "Com base nas anteriores documentação, vamos definir o modelo de base como um único neurónio, com apenas um peso e uma polarização da seguinte forma:\n",
    "! [](https://user-images.githubusercontent.com/5733246/52482541-ad0f5f80-2b98-11e9-927c-a37ead68bf90.png)\n",
    "[This reference](https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc) pode ser útil para a definição de um modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-suaOvTD2Mj"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies \n",
    "# TODO: Import the sequential model - https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "# TODO: Import the dense layer - https://keras.io/layers/core/\n",
    "\n",
    "# TODO: Import the SGD optimizer - https://keras.io/optimizers/\n",
    "\n",
    "# 1. Define your base model here\n",
    "# TODO: Assign Sequential to model and create a list with just one Dense layer with one unit and one input\n",
    "model = None\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "# TODO: Initialize the Stochastic Gradient Descent optimizer\n",
    "\n",
    "# TODO: Use the model.compile method with the inputs 'optimizer' and 'loss'\n",
    "model.compile(...)\n",
    "\n",
    "# 3. Train your model\n",
    "# TODO: Use the model.fit method with the the training data as input\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBamRQyDD2Mu"
   },
   "source": [
    "## 4. Previsões Verificação\n",
    "Agora vamos ver o quão bem a nossa previsão de base está realizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yv2FyIkjD2Mv"
   },
   "outputs": [],
   "source": [
    "def check_predictions(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X, y, c='b', alpha=0.5, label=\"Data\")\n",
    "    plt.plot(X, y_pred, c='r', label=\"Model\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()\n",
    "    \n",
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ni6ssLlzD2M5"
   },
   "source": [
    "## 5. Resultados de Melhoria\n",
    "Podemos ver que o modelo não é apropriado também no conjunto de dados. Vamos agora melhorar esses resultados! Aqui estão algumas coisas básicas que vamos tentar:\n",
    "1. Aumentar o número de épocas\n",
    "- Épocas é o número de vezes que o algoritmo vê todo o conjunto de dados. Para simplificar, você pode pensar aqui como o número de iterações do peso\n",
    "2. Alterar o otimizador\n",
    "- descida gradiente estocástico é muito simples otimizadores. Há mais robusts otimizadores como Adam\n",
    "3. Alterar a taxa de aprendizagem\n",
    "4. Adição de mais camadas\n",
    "### 5.1 O aumento do número de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o2dluRgD2M9"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "opt = SGD()\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSi1UI9xD2NI"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmP1J08_D2Nz"
   },
   "source": [
    "### 5.2 Verificação outros otimizadores\n",
    "Aqui está um grande repositório comparando diferentes otimizadores de TensorFlow: https://github.com/Jaewan-Yun/optimizer-visualization\n",
    "! [](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)\n",
    "! [](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)\n",
    "Vamos agora tentar outros otimizadores que estão disponíveis a partir da documentação: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Jbl-m28D2N0"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer loss function here\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2j9oZafD2N4"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUFb9u6yD2OA"
   },
   "source": [
    "### 5.3 Ajustando o aprendizado Taxa\n",
    "Finalmente vamos aumentar a taxa de aprendizagem. Como um lembrete, valores pequenos requer mais iterações, enquanto grandes valores tornar o modelo a divergir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1NTbeGYD2OC"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "opt = Adam(lr=0.1) # Default of adam is 0.001. Check large and small values, use a value slighly lower than a diverging lr\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78M6Bf10D2OM"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "untxwrvTD2OR"
   },
   "source": [
    "## Final considerations\n",
    "Finalmente, também pode tentar usar mais camadas no modelo. No entanto, vamos discutir isso no próximo vídeo, após verificar as diferentes funções de ativação que podem ser usados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsT_754AD2OS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "toy-problem-blank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
