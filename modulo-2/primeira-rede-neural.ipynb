{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/WittmannF/udemy-deep-learning/blob/master/section-2/toy_problem_blank.ipynb\" target=\"_parent\"> <img src =\" https://colab.research.google.com/assets/colab-badge.svg\" alt = \"Open In Colab\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j7a4139FPMIc"
   },
   "source": [
    "# Sua Primeira Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PWEfDAEePLJW"
   },
   "source": [
    "Vamos usar o mesmo exemplo que temos visto no vídeo anterior com o preço de casa com base em sua área:\n",
    "![input-example](https://user-images.githubusercontent.com/5733246/52136634-a2e8e080-262f-11e9-8f7a-61d79831d83d.png)\n",
    "Normalmente, quando se trabalha com problemas de aprendizagem de máquina ou profunda aprendizagem, você terá que seguir esses cinco passos:\n",
    "\n",
    "1. Explorando os dados\n",
    "   - Importação de dados\n",
    "   - Compreender os dados\n",
    "\n",
    "2. Preparar os dados\n",
    "   - Scaling\n",
    "   - Transformando\n",
    "   - One-Hot Encoding\n",
    "   - Train teste de divisão\n",
    "\n",
    "3. Desenvolver um modelo básico\n",
    "4. Verificação das Previsões\n",
    "5. Melhoria dos Resultados\n",
    "\n",
    "## 1. Importar os Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uOIDW9boibxW"
   },
   "source": [
    "Vamos criar um conjunto de dados brinquedo na mão, com apenas 20 áreas e 20 preços:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDaYfd4yD2Lj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IpettqxCD2L8"
   },
   "source": [
    "## 2. Preparando os Dados\n",
    "### Escalando Atributos Numéricos\n",
    "Otimizadores funcionam melhor quando os dados de entrada estão dentro de uma mesma escala, por exemplo de -1 a 1 ou entre 0 a 1. Isto ajuda a superfície de erro para aproximar mais rápido para o mínimo global. Para melhores resultados, o método chamando [Standardization (Padronização ou Uniformização)](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) é altamente sugerido pois converte a média para zero e o desvio padrão para 1. \n",
    "- Para familiarização com Desvio Padrão e Média, recomendo a seguinte leitura: https://medium.com/data-science-br/reproduzindo-uma-distribui%C3%A7%C3%A3o-normal-jogando-cara-ou-coroa-e6d77b490b91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aSO0XZn8ibxu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_0CxDqZbD2MQ"
   },
   "source": [
    "### Divisão dos Dados em Conjuntos de Treinamento e Teste\n",
    "Além de escalar os dados, é muito importante para dividir o conjunto de dados para treinamento e teste. O conjunto de treinamento vai ser usado para ajustar o modelo (ou fronteira de decisão) e o conjunto de teste vai ser usado para avaliar o seu desempenho em dados não vistos. Se não utilizar um conjunto de teste, há um risco de a rede neural \"memorizar\" os dados de treinamento, fenômeno conhecido por **overfitting**, ilustrado a seguir:\n",
    "![underfit](https://i.ytimg.com/vi/dBLZg-RqoLg/maxresdefault.jpg)\n",
    "\n",
    "\n",
    "Podemos usar a biblioteca de machine learning scikit-learn para a divisão treino/teste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UmBmrkd4D2MR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KPiwW_lsQXV8"
   },
   "source": [
    "## 3. Desenvolver um modelo base\n",
    "Três componentes que você precisa ter ciência:\n",
    "- Arquitetura: Número de camadas ocultas e neuronios em cada camada\n",
    "   - https://keras.io/layers/core/\n",
    "   - https://keras.io/getting-started/sequential-model-guide/\n",
    "- Otimizadores e Função de Custo\n",
    "   - https://keras.io/optimizers/\n",
    "   - https://keras.io/losses/\n",
    "   - https://keras.io/models/sequential/#compile\n",
    "   \n",
    "- Treinar o modelo:\n",
    "   - https://keras.io/models/sequential/#fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J-suaOvTD2Mj"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies \n",
    "# TODO: Import the sequential model - https://keras.io/getting-started/sequential-model-guide/\n",
    "\n",
    "# TODO: Import the dense layer - https://keras.io/layers/core/\n",
    "\n",
    "# TODO: Import the SGD optimizer - https://keras.io/optimizers/\n",
    "\n",
    "# 1. Define your base model here\n",
    "# TODO: Assign Sequential to model and create a list with just one Dense layer with one unit and one input\n",
    "model = None\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "# TODO: Initialize the Stochastic Gradient Descent optimizer\n",
    "\n",
    "# TODO: Use the model.compile method with the inputs 'optimizer' and 'loss'\n",
    "model.compile(...)\n",
    "\n",
    "# 3. Train your model\n",
    "# TODO: Use the model.fit method with the the training data as input\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IBamRQyDD2Mu"
   },
   "source": [
    "## 4. Verificar Previsões\n",
    "Agora vamos ver o quão bem a nossa previsão de base está realizando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Yv2FyIkjD2Mv"
   },
   "outputs": [],
   "source": [
    "def check_predictions(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    plt.scatter(X, y, c='b', alpha=0.5, label=\"Data\")\n",
    "    plt.plot(X, y_pred, c='r', label=\"Model\")\n",
    "    plt.legend(loc=0)\n",
    "    plt.show()\n",
    "    \n",
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ni6ssLlzD2M5"
   },
   "source": [
    "## 5. Melhoria de Resultados\n",
    "Podemos ver que o modelo não é apropriado. Vamos agora melhorar esses resultados! Aqui estão algumas coisas básicas que vamos tentar:\n",
    "1. Aumentar o número de épocas\n",
    "- Épocas é o número de vezes que o algoritmo vê todo o conjunto de dados. \n",
    "2. Alterar o otimizador\n",
    "- Descida gradiente estocástico é muito simple. Há otimizadores mais robustos como Adam\n",
    "3. Alterar a taxa de aprendizagem (learning rate)\n",
    "4. Adição de mais camadas\n",
    "\n",
    "### 5.1 Aumentar o número de épocas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9o2dluRgD2M9"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "opt = SGD()\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kSi1UI9xD2NI"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RmP1J08_D2Nz"
   },
   "source": [
    "### 5.2 Trocar de Otimizadores\n",
    "Ótimo repositório comparando diferentes otimizadores de TensorFlow: https://github.com/Jaewan-Yun/optimizer-visualization\n",
    "![](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)\n",
    "![](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)\n",
    "\n",
    "Vamos agora tentar outros otimizadores que estão disponíveis a partir da documentação: https://keras.io/optimizers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Jbl-m28D2N0"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer loss function here\n",
    "opt = Adam()\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N2j9oZafD2N4"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iUFb9u6yD2OA"
   },
   "source": [
    "### 5.3 Alterando o Learning Rate (Taxa de Aprendizagem)\n",
    "Finalmente vamos aumentar a taxa de aprendizagem. Como um lembrete, valores pequenos requer mais iterações, enquanto grandes valores tornar o modelo a divergir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E1NTbeGYD2OC"
   },
   "outputs": [],
   "source": [
    "# 0. Import keras dependencies here\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# 1. Define your base model here\n",
    "model = Sequential([\n",
    "        Dense(units=1, input_shape=(1,))\n",
    "    ])\n",
    "\n",
    "# 2. Set your optimizer and loss function here\n",
    "opt = Adam(lr=0.1) # Default of adam is 0.001. Check large and small values, use a value slighly lower than a diverging lr\n",
    "model.compile(optimizer=opt,\n",
    "             loss='mean_squared_error')\n",
    "\n",
    "\n",
    "# 3. Train your model\n",
    "model.fit(X_train, y_train, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "78M6Bf10D2OM"
   },
   "outputs": [],
   "source": [
    "check_predictions(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Adição de Camadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MsT_754AD2OS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "include_colab_link": true,
   "name": "toy-problem-blank.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
